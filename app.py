import streamlit as st
# from chain import retrieval_chain
from chain_vllm import retrieval_chain
from langfuse.langchain import CallbackHandler

handler = CallbackHandler()
# -------- Streamlit UI ----------
st.set_page_config(page_title="Chat v·ªõi FAISS + Azure OpenAI", page_icon="ü§ñ")
st.title("üí¨ Chatbot FAISS + Azure OpenAI")

# L∆∞u l·ªãch s·ª≠ chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input chat
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n..."):
    # Hi·ªÉn th·ªã c√¢u h·ªèi ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        # G·ªçi LLM chain
        # answer = retrieval_chain.invoke(prompt)
        ai_message = ""
        for token in retrieval_chain.stream(prompt):
            ai_message+= token
            placeholder.markdown(ai_message)
        # answer = result.get("answer") or result.get("context")

        # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi
        st.session_state.messages.append({"role": "assistant", "content": ai_message})
        