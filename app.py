import streamlit as st
from chain import retrieval_chain
from langfuse.langchain import CallbackHandler

handler = CallbackHandler()
# -------- Streamlit UI ----------
st.set_page_config(page_title="Chat v·ªõi FAISS + Azure OpenAI", page_icon="ü§ñ")
st.title("üí¨ Chatbot FAISS + Azure OpenAI")

# L∆∞u l·ªãch s·ª≠ chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input chat
if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n..."):
    # Hi·ªÉn th·ªã c√¢u h·ªèi ng∆∞·ªùi d√πng
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # G·ªçi LLM chain
    result = retrieval_chain.invoke({"input": prompt}, config={
                                                                "callbacks": [handler],
                                                                "metadata": {"user_id": "123", "session": "abc"}
                                                            })
    answer = result.get("answer") or result.get("context")

    # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi
    st.session_state.messages.append({"role": "assistant", "content": answer})
    with st.chat_message("assistant"):
        st.markdown(answer)